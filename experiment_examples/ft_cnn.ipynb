{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Fine-Tuning the CNN Filter"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a605b9ab697d21df"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24.3\n",
      "2.8.4\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "print(numpy.__version__)\n",
    "import networkx\n",
    "\n",
    "print(networkx.__version__)\n",
    "\n",
    "from nilmtk.api import API\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from nilmtk.disaggregate import GaterCNN\n",
    "import nilmtk.utils as utils\n",
    "\n",
    "import torch\n",
    "\n",
    "USE_GPU = True\n",
    "device = torch.device(\"cuda:0\" if USE_GPU and torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.__version__, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Selection\n",
    "\n",
    "We begin by specifying the fine-tuning data and corresponding file paths.\n",
    "\n",
    "The fine-tuning process is performed per appliance per house, i.e., one appliance in one house at a time.\n",
    "\n",
    "The fine-tuning data can be selected with flexible duration and time range, provided that the following conditions are met:\n",
    "1. The fine-tuning dataset includes at least one active usage event of the target appliance.\n",
    "2. There is no overlap between the fine-tuning data and the testing data."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20a9ec56fd833a8c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "DATASET_NAME = 'redd'\n",
    "HOUSE = 3\n",
    "TUNED_GATER = True\n",
    "TUNE = False\n",
    "APPLIANCE = \"microwave\"\n",
    "\n",
    "# Fine-tunes with one day data or seven days data\n",
    "days = 1\n",
    "\n",
    "CSV_PATH = f\"./csv_ft/{days}days_{APPLIANCE}_{HOUSE}_GATE={TUNED_GATER}_DM={TUNE}.csv\"\n",
    "MODEL_NOTE = f\"{days}days_ft_{HOUSE}\"\n",
    "\n",
    "# Whether to perform the fine-tuning\n",
    "# If TUNED_GATER == False, the code does not fine-tune anything and will test the raw model on target dataset directly.\n",
    "if TUNED_GATER:\n",
    "    GATER_PATH = f\"./{APPLIANCE}_ft_{HOUSE}_cnn_best_state_dict.pt\"\n",
    "else:\n",
    "    GATER_PATH = f\"./{APPLIANCE}_ukdale_cnn_best_state_dict.pt\"\n",
    "\n",
    "if HOUSE == 1:\n",
    "    TRAIN = {\n",
    "        # 1: {  # data for 7-days\n",
    "        #     'start_time': '2011-04-19',\n",
    "        #     'end_time': '2011-04-26'\n",
    "        # },\n",
    "        1: {  # data for one-day\n",
    "            'start_time': '2011-04-23',\n",
    "            'end_time': '2011-04-24'\n",
    "        },\n",
    "    }\n",
    "    TEST = {\n",
    "        1: {\n",
    "            'start_time': '2011-04-24',\n",
    "            'end_time': '2011-05-26'\n",
    "        },\n",
    "    }\n",
    "elif HOUSE == 2:\n",
    "    TRAIN = {\n",
    "        # 2: {  # data for 7-days\n",
    "        #     'start_time': '2011-04-18',\n",
    "        #     'end_time': '2011-04-25'\n",
    "        # },\n",
    "        2: {  # one-day data for D.W. and M.V.\n",
    "            'start_time': '2011-04-18',\n",
    "            'end_time': '2011-04-19'\n",
    "        },\n",
    "        # 2: {  # one-day data for W.M.\n",
    "        #     'start_time': '2011-04-23',\n",
    "        #     'end_time': '2011-04-24'\n",
    "        # },\n",
    "    }\n",
    "    TEST = {\n",
    "        2: {\n",
    "            'start_time': '2011-04-25',\n",
    "            'end_time': '2011-05-22'\n",
    "        },\n",
    "    }\n",
    "elif HOUSE == 3:\n",
    "    TRAIN = {\n",
    "        # 3: {  # data for 7-days\n",
    "        #     'start_time': '2011-04-17',\n",
    "        #     'end_time': '2011-04-24'\n",
    "        # },\n",
    "        3: {  # one-day data for D.W. and M.V.\n",
    "            'start_time': '2011-04-17',\n",
    "            'end_time': '2011-04-18'\n",
    "        },\n",
    "        # 3: {  # one-day data for W.M.\n",
    "        #     'start_time': '2011-04-19',\n",
    "        #     'end_time': '2011-04-20'\n",
    "        # },\n",
    "    }\n",
    "    TEST = {\n",
    "        3: {\n",
    "            'start_time': '2011-04-24',\n",
    "            'end_time': '2011-05-30'\n",
    "        },\n",
    "    }\n",
    "else:\n",
    "    raise NameError"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50d345f5a05c97ac"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine-Tune\n",
    "\n",
    "Then, we perform the fine-tuning process."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbf32dcbed193752"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6cc5f0a00029dd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = {\n",
    "    # Specify power type, sample rate and disaggregated appliance\n",
    "    'power': {\n",
    "        'mains_train': ['apparent'],\n",
    "        'mains_transfer': ['apparent'],\n",
    "        'mains_test': ['apparent'],\n",
    "        'appliance': ['active'],\n",
    "    },\n",
    "    'sample_rate': 6,\n",
    "    'appliances': [APPLIANCE],\n",
    "    # 'appliances': ['fridge'],\n",
    "    # Universally no pre-training\n",
    "    'pre_trained': False,\n",
    "    \"app_meta\": utils.GENERAL_APP_META,\n",
    "    # Specify algorithm hyper-parameters\n",
    "    'save_note': f'ft-{HOUSE}' if TUNE else f'ft-{HOUSE}-no',\n",
    "    'methods': {\n",
    "        \"GaterCNN\": GaterCNN(\n",
    "            {\n",
    "                'n_epochs': 20,\n",
    "                'batch_size': 128,\n",
    "                'sequence_length': 720,\n",
    "                'appliance_length': 720,\n",
    "                # In fine-tuning mode, set 'test_only' to True to avoid the model from\n",
    "                # being trained by the source dataset again.\n",
    "                'test_only': True,\n",
    "                'fine_tune': TUNE,\n",
    "                'note': MODEL_NOTE,\n",
    "                'load_from': 'ukdale',\n",
    "                'patience': 3\n",
    "            }\n",
    "        )\n",
    "    },\n",
    "    # Specify train and test data\n",
    "    'train': {\n",
    "        'datasets': {\n",
    "            'redd': {\n",
    "                'path': '../mnt/redd.h5',\n",
    "                'buildings': TRAIN\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "    'transfer': {\n",
    "        'datasets': {\n",
    "            'redd': {\n",
    "                'path': '../mnt/redd.h5',\n",
    "                'buildings': TRAIN\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    'test': {\n",
    "        'datasets': {\n",
    "            'redd': {\n",
    "                'path': '../mnt/redd.h5',\n",
    "                'buildings': TEST\n",
    "            },\n",
    "        },\n",
    "        # Specify evaluation metrics\n",
    "        'metrics': ['accuracy', 'f1score', 'mae', 'sae', 'wssim']\n",
    "    }\n",
    "}\n",
    "\n",
    "API(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
